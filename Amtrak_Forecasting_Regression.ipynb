{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXjOHqz4SF3N2GwULkePYD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sidagarwal-labs/DSBA-6211---Advance-Business-Analytics/blob/main/Amtrak_Forecasting_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "PY4sze6kMXH3",
        "outputId": "cd69a8b8-3d96-463c-d673-b4bc589ad837"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Amtrak.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1457500517.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#import the dataset and read the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Amtrak.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Amtrak.csv'"
          ]
        }
      ],
      "source": [
        "#import the dataset and read the data\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"Amtrak.csv\")\n",
        "df.describe(include='all')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#read the data\n",
        "df"
      ],
      "metadata": {
        "id": "CqHzX4JcNewM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info"
      ],
      "metadata": {
        "id": "QZDM1iQ_NnKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert the data to time series\n",
        "df['Date'] = pd.to_datetime(df.Month, format='%d/%m/%Y')"
      ],
      "metadata": {
        "id": "LACeUhMNNgtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create rider time series\n",
        "rider_ts = pd.Series(df.Ridership.values,\n",
        "                     index=df.Date,\n",
        "                     name='Ridership')"
      ],
      "metadata": {
        "id": "WCm6oLe3OFss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rider_ts"
      ],
      "metadata": {
        "id": "uVKdkltIOg6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot the time series\n",
        "import matplotlib.pyplot as plt\n",
        "ax=rider_ts.plot()\n",
        "ax.set_xlabel('Time')\n",
        "ax.set_ylabel('Ridership (in 000s)')\n",
        "ax.set_ylim(1300,2300)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fexCHkPgOn_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we see some seasonality/trend\n",
        "#intially decreasing, but has started increasing since 1997\n",
        "#now we will do a time based data partition to focus on recent data points\n",
        "#train is older data, test is newer data\n",
        "\n",
        "nValid = 36 #3 years so 12*3 = past 36 months\n",
        "nTrain=len(rider_ts)-nValid #everything minus the past 36 months is training\n",
        "train_ts=rider_ts[:nTrain]\n",
        "valid_ts=rider_ts[nTrain:]"
      ],
      "metadata": {
        "id": "Sgy9GHCmPJWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lets look at the training dataset\n",
        "train_ts"
      ],
      "metadata": {
        "id": "Pd-ykDGJPvqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create regression based model\n",
        "import statsmodels.formula.api as sm\n",
        "from statsmodels.tsa import tsatools, stattools"
      ],
      "metadata": {
        "id": "v95iZFV_P36D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create dataframe for regression based models\n",
        "#add trend for the entire time series (train and test)\n",
        "#create dummy variable for modeling months\n",
        "ts_df = tsatools.add_trend(rider_ts, trend='ct')\n",
        "ts_df['Month']=ts_df.index.month"
      ],
      "metadata": {
        "id": "zi1YVH1NQDhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ts_df"
      ],
      "metadata": {
        "id": "5SfWaXwHQmNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split dataframe\n",
        "nValid = 36\n",
        "nTrain=len(ts_df)-nValid\n",
        "train_df=ts_df[:nTrain]\n",
        "valid_df=ts_df[nTrain:]\n",
        "\n",
        "#train first regression model with linear trend\n",
        "rider_lm=sm.ols(formula='Ridership ~ trend', data=train_df).fit()"
      ],
      "metadata": {
        "id": "Yf-kN8l9Q7Gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the model summary\n",
        "#notice how trend, Beta 1 has a coeff of 0.35 but the p value is 0.39\n",
        "#this is greater than 0.05. We expect this since the trend only impacts some of the data.\n",
        "#the p value for beta 1 will be high and insignificant in linear trends\n",
        "rider_lm.summary()"
      ],
      "metadata": {
        "id": "wZZHIqssRSvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now lets check model performance on the validation set\n",
        "! pip install dmba\n",
        "from dmba import regressionSummary"
      ],
      "metadata": {
        "id": "cTkgllN8SOf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lets check the model performance\n",
        "predict_lm=rider_lm.predict(valid_df)\n",
        "regressionSummary(valid_ts,predict_lm)"
      ],
      "metadata": {
        "id": "V2aRlft7TR7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lets create model version 2\n",
        "#linear trend model with quad, polynomial trend\n",
        "\n",
        "import numpy as np\n",
        "rider_lm_poly=sm.ols(formula='Ridership ~ trend + np.square(trend)', data=train_df).fit()"
      ],
      "metadata": {
        "id": "hid2t7kmThIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now lets look at the model results\n",
        "#notice now beta 1 and beta 2 are both stat sig\n",
        "rider_lm_poly.summary()"
      ],
      "metadata": {
        "id": "9fyhOBCtT79T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now lets check the model performance\n",
        "#notice how MAPE is lower (7.08) for this model than linear trend (10.15)\n",
        "#this is a better model\n",
        "predict_lm_poly=rider_lm_poly.predict(valid_df)\n",
        "regressionSummary(valid_ts,predict_lm_poly)"
      ],
      "metadata": {
        "id": "rXaITY0jUVaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create model #3 for seasonality per month\n",
        "#notice how the P value is under 0.05 for all except month 2, February.\n",
        "#This means the difference between January vs February is insignifiant. Since 0 is January.\n",
        "#cannot drop a dummy\n",
        "rider_lm_season = sm.ols(formula='Ridership~C(Month)', data=train_df).fit()\n",
        "rider_lm_season.summary()"
      ],
      "metadata": {
        "id": "7ezt1JINWzFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the model score of seasonality model\n",
        "#notice how MAPE is higher, so technically without seasonality is better\n",
        "predict_lm_season=rider_lm_season.predict(valid_df)\n",
        "regressionSummary(valid_ts,predict_lm_season)"
      ],
      "metadata": {
        "id": "V6T6ZZSMYF6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create model 4, trend and seasonality\n",
        "#look at the model summary\n",
        "modelformula = 'Ridership ~ trend + np.square(trend)+C(Month)'\n",
        "rider_lm_trendseason = sm.ols(formula=modelformula, data=train_df).fit()\n",
        "rider_lm_trendseason.summary()"
      ],
      "metadata": {
        "id": "rKrJs4XhYPVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now lets check model summary of model 4\n",
        "#notice how this has the lowest MAPE @ 6.7\n",
        "predict_lm_trendseason=rider_lm_trendseason.predict(valid_df)\n",
        "regressionSummary(valid_ts,predict_lm_trendseason)"
      ],
      "metadata": {
        "id": "inWTpxPgZ-Gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a simple moving average model based on last 12 months\n",
        "ma = train_ts.rolling(12).mean()"
      ],
      "metadata": {
        "id": "Bof7N2QbCyyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#notice how first 11 rows will be blank since there is not enough historic data\n",
        "ma"
      ],
      "metadata": {
        "id": "0wrQwVY-Detu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_ma=ma[-1]"
      ],
      "metadata": {
        "id": "OQ4W2eFaD37a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_ma"
      ],
      "metadata": {
        "id": "ptSzPv-DEGZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forecasting based on last_ma\n",
        "predict_ma = pd.Series(last_ma,index=valid_ts.index)\n",
        "predict_ma"
      ],
      "metadata": {
        "id": "P2VR7AErElvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#summary of stats of simple moving average on actual\n",
        "regressionSummary(valid_ts, predict_ma)"
      ],
      "metadata": {
        "id": "g1iC0OIIERwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create exponential smoothing model\n",
        "from statsmodels.tsa.api import SimpleExpSmoothing\n",
        "SES = SimpleExpSmoothing(train_ts, initialization_method='estimated').fit()"
      ],
      "metadata": {
        "id": "FlS4VN97EoGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alphas = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
        "\n",
        "print(\"Testing different alpha values for Simple Exponential Smoothing:\")\n",
        "for alpha in alphas:\n",
        "    print(f\"\\n--- Alpha = {alpha} ---\")\n",
        "    SES_fixed_alpha = SimpleExpSmoothing(train_ts, initialization_method=None).fit(smoothing_level=alpha)\n",
        "    predict_SES_fixed_alpha = SES_fixed_alpha.forecast(len(valid_ts))\n",
        "    print(f\"SES model parameters with alpha={alpha}:\\n{SES_fixed_alpha.model.params}\")\n",
        "    print(\"Performance with fixed alpha:\")\n",
        "    regressionSummary(valid_ts, predict_SES_fixed_alpha)\n"
      ],
      "metadata": {
        "id": "QWz8U2RVFLx6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}